1、x86系列CPU都是little-endian的字节序(低位字节放低地址位)。

2、网络字节顺序采用big endian排序方式(高位字节放低地址位)。

3、在使用little endian的系统中，这些函数会把字节序进行转换；
   在使用big endian类型的系统中，这些函数会定义成空宏；
   同样，在网络程序开发时 或是跨平台开发时，也应该注意保证只用一种字节序，不然两方的解释不一样就会产生bug。
   
4、点分十进制（Dotted Decimal Notation）全称为点分（点式）十进制表示法，是IPv4的IP地址标识方法。

5、epoll支持一个进程打开的socket描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）；I/O效率不会随着FD数目的增加而线性下降；mmap加速；epoll api简洁

6、句柄可以使一种标识，能够标识模块、任务、实例、文件等，实际上句柄就是用来间接标识对象在内存中的位置，句柄是由系统分配的，由win api分配这些确定的句柄，并且返回给应用程序

7、GDI对象--graphics devices interface

8、句柄地址（稳定）->记载着对象在内存中的地址->对象在内存中的地址（不稳定）->实际对象。但是，必须注意注意的是，程序每次重新启动，系统不能保证分配给这个程序的句柄还是原来的那个句柄，而且绝大多数情况的确是不一样的。同理就是，句柄地址->标识对象内存地址，实际上就是句柄就是指向指针的指针。

9、linux 读写socket通过socket描述符由内核操作并通知用户空间

10、mmap：mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。也就是说一个socket描述符的消息内核空间能直接通过mmap映射方法来通知用户空间。

11、com.bio:一个线程只能处理一下一个客户端连接，性能瓶颈

12、伪异步I/O:线程池优化由传统bio带来的性能瓶颈，但没有解决根本问题

13、输入输出流的读写方法都是同步阻塞的  

14、nio中操作数据都是在buffer缓冲区进行的；全双工管道channel；多路复用器selector

15、一个多路复用器selector可以同时轮询多个channel，由于jdk使用epoll()替代传统的selector实现，所以他并没有最大连接句柄限制，也就意味着只需要一个负责轮询selector的线程就可以接入成千上万的channel.

16、缓冲区的设计是类似异步IO的实现

17、连接，读取，写入；请求->解码->计算->编码->响应；事件驱动，事件触发，轮询机制

18、socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024));
    socketChannel.pipeline().addLast(new StringDecoder());
    按行切换的文本解码器.

19、DelimiterBaseFrameDecoder、FixedLengthFrameDecoder,前者可以自动完成以分隔符做结束标志的消息解码器，后者可以自动完成定长消息的解码

20、编解码框架:google:protobuf不支持半包处理 facebook:thrift jboss:marshalling支持半包处理

21、ObjectDecoder,ObjectEncoder编解码器

22、http协议，请求消息：请求行，消息头，消息正文；响应消息：状态行，消息报头，响应正文

23、http+xml,RESTful+json,pojo-xml,JiBX绑定框架,dom4j,xml注解

24、全双工与半双工，单一tcp连接

25、websocket生命周期，以太网帧格式，ip帧格式，tcp帧格式，udp帧格式，http帧格式

26、传统io，字节流io stream，字符流 reader writer；nio FileChannel

27、通过一个文件打流来打开一个FileChannel，通过byteBuffer读写

28、netty中的discard 类比 nio中的compact方法,clear并不会清空缓冲区本身，而是还原可读索引和可写索引的初始值，mark rest

29、创建一个ByteBuf的视图derived buffers

30、nioBuffer()转换方法不能感知到ByteBuf的动态扩张操作，随机读写操作不支持动态扩张

31、byteBuf 从内存分配上：可以分为 堆内存和直接内存两类,heapByteBuf分配和回收速度快，亲和jvm，但是进行io读写时需要从堆内存复制到内核中的通道channel中，多复制一次会带来性能损耗；直接内存相比于堆内存分配和回收速率会比较慢，但是由于更贴近内核，少了一次复制，所以性能上会更高一些。一般来说，在io通信上可以用直接内存读写，后端编解码贴近jvm的用堆内存读写，这样的组合性能是最优的。
            从内存回收上：分为对象池与单一byteBuf，对象池在性能上更加稳定。
            
32、resourceLeakDetector，倍增与步进，对象池Pooled与非对象池UnPooled，ByteBufUtil

33、netty基于事件驱动，channel进行io操作时，都会产生io事件，然后驱使channelPipline传播到对应的handler类中，进行拦截并处理，性能上事件驱动的netty框架会比传统aop切面编程的性能好

34、channel的注册操作是讲selectionKey注册到多路复用器上，用过key值可以获取当前的channel

35、channel的循环发送次数的限制是为了避免线程一直尝试io操作

36、backlog可以设置客户端等待的最大长度，操作完成后会通知ChannelFuture，将Channel注册到EventLoop的多路复用器上

37、实际的网络io基本都是由unsafe类实现的，如果是其他线程注在多路复用器eventLoop上进行注册操作，多路复用器现将这个操作封装成一个可执行的Runnable线程，使其能够在多路复用器的任务队列上执行

38、写操作不会被阻塞，读操作可以动态变更buffer中的大小，考虑tcp半包，读的最大字节数，连续操作的上限次数为16次

39、inbound事件(fireXXX) 从IO线程流向用户业务handler，outbound事件：out事件一般由用户主动发起网络io操作，例如用户发起的链接，绑定，消息发送操作，in事件：tcp建立链接，读操作

40、ctx.fireChannelActive();//channel激活事件

41、ChannelPipelin是线程安全的并且支持运行时动态修改，负责io事件调度

42、messageTomessageDecoder 二次解码器 姜tcp数据包转换成pojo对象

43、LengthFieldBasedFrameDecoder(可配置？半包解码器)调整参数获取多种解码方式

44、netty线程模型，多个串行化的线程并行运行，局部无锁化

45、最佳化：两个EventLoopGroup，隔离连接与io操作，减少启动用户线程尽量都放在channelHandler中进行，逻辑处理简单可直接在nio线程上处理，复杂的话将用户线程封装成task放入消息队列中执行

46、几个公式：线程数量 = （线程总时间/瓶颈资源时间）* 瓶颈资源的线程并行数
             qps = 1000/线程总时间 * 线程数
             
47、NioEventLoop：io读写，系统task，定时任务schedule，提供用户定制的io与task的比例时间，默认是50%

48、future相关的异步操作，channelFuture两个状态complete与uncomplete状态，添加监听器来判断io操作是否完成

49、java内存交互协议，volatile两个特性：线程可见性，禁止指令重排序优化

50、附录后面的参数配置表
